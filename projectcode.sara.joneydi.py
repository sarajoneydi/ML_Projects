# -*- coding: utf-8 -*-
"""Untitled23.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KwgIhnNNZK1_0jMdnDRoGAiM7JTdvzKb
"""

## Project Implementation-- Sara Joneydi
import numpy as np
import pandas as pd
import datetime as dt
import sklearn
from scipy import stats
from sklearn import preprocessing
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import recall_score as rs
from sklearn.metrics import precision_score as ps
from sklearn.metrics import f1_score as fs
from sklearn.metrics import log_loss

encoder = preprocessing.LabelEncoder()

## Data Pre processing:
data = pd.read_csv('data.csv')
data = data.drop('id',axis=1)
data = data.fillna(np.nan,axis=0)
data['location'] = encoder.fit_transform(data['location'].astype(str))
data['country'] = encoder.fit_transform(data['country'].astype(str))
data['gender'] = encoder.fit_transform(data['gender'].astype(str))
data[['symptom1']] = encoder.fit_transform(data['symptom1'].astype(str))
data[['symptom2']] = encoder.fit_transform(data['symptom2'].astype(str))
data[['symptom3']] = encoder.fit_transform(data['symptom3'].astype(str))
data[['symptom4']] = encoder.fit_transform(data['symptom4'].astype(str))
data[['symptom5']] = encoder.fit_transform(data['symptom5'].astype(str))
data[['symptom6']] = encoder.fit_transform(data['symptom6'].astype(str))

data['sym_on'] = pd.to_datetime(data['sym_on'])
data['hosp_vis'] = pd.to_datetime(data['hosp_vis'])
data['sym_on']= data['sym_on'].map(dt.datetime.toordinal)
data['hosp_vis']= data['hosp_vis'].map(dt.datetime.toordinal)
data['diff_sym_hos']= data['hosp_vis'] - data['sym_on']

data['diff_symp_hos'] = data['hosp_vis']-data['sym_on']

data = data.drop(['sym_on','hosp_vis'],axis=1)

print(data.dtypes)

## Pre Processing Train Data for Training:
tdata = pd.read_csv('train.csv')
print(tdata.head())

tdata = pd.read_csv('train.csv')
tdata = tdata.drop('id',axis=1)
tdata = tdata.fillna(np.nan,axis=0)
tdata['age'] = tdata['age'].fillna(value=tdata['age'].mean())
tdata['location'] = encoder.fit_transform(tdata['location'].astype(str))
tdata['country'] = encoder.fit_transform(tdata['country'].astype(str))
tdata['gender'] = encoder.fit_transform(tdata['gender'].astype(str))
tdata[['symptom1']] = encoder.fit_transform(tdata['symptom1'].astype(str))
tdata[['symptom2']] = encoder.fit_transform(tdata['symptom2'].astype(str))
tdata[['symptom3']] = encoder.fit_transform(tdata['symptom3'].astype(str))
tdata[['symptom4']] = encoder.fit_transform(tdata['symptom4'].astype(str))
tdata[['symptom5']] = encoder.fit_transform(tdata['symptom5'].astype(str))
tdata[['symptom6']] = encoder.fit_transform(tdata['symptom6'].astype(str))

tdata['sym_on'] = pd.to_datetime(tdata['sym_on'])
tdata['hosp_vis'] = pd.to_datetime(tdata['hosp_vis'])
tdata['sym_on']= tdata['sym_on'].map(dt.datetime.toordinal)
tdata['hosp_vis']= tdata['hosp_vis'].map(dt.datetime.toordinal)
tdata['diff_sym_hos']= tdata['hosp_vis'] - tdata['sym_on']

tdata = tdata.drop(['sym_on','hosp_vis'],axis=1)
print(tdata)

print(tdata.isna().sum())

## import Evaluation Metrics:

from sklearn.metrics import recall_score as rs
from sklearn.metrics import precision_score as ps
from sklearn.metrics import f1_score as fs
from sklearn.metrics import balanced_accuracy_score as bas
from sklearn.metrics import confusion_matrix as cm

## Logistic Regression:
from sklearn.linear_model import LogisticRegression as lr

classifier = lr()

X = tdata[['location','country','gender','age','vis_wuhan','from_wuhan','symptom1',
           'symptom2','symptom3','symptom4','symptom5','symptom6','diff_sym_hos']]
Y = tdata['death']

X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=10)
classifier.fit(X_train,np.array(Y_train).reshape(Y_train.shape[0],1))

## Evaluation of the Model:

pred = np.array(classifier.predict(X_test))
recall_lr = rs(Y_test,pred)
precision_lr = ps(Y_test,pred)
f1_lr = fs(Y_test,pred)
ma_lr = classifier.score(X_test,Y_test)

print('*** Evaluation metrics for test dataset ***\n')
print('Recall Score: ',recall_lr)
print('Precision Score: ',precision_lr)
print('F1 Score: ',f1_lr)
print('Accuracy: ',ma_lr)
a = pd.DataFrame(Y_test)
a['pred']= classifier.predict(X_test)
print('\n\tTable \n')
print(a.head())

import matplotlib.pyplot as plt

plt.bar(['Accuracy','F1 Score','Recall Score','Precision Score'],
        [ma_lr,f1_lr,recall_lr,precision_lr],color=['red','Blue','green','Yellow'])
plt.plot([ma_lr,f1_lr,recall_lr,precision_lr],color='black')
plt.title('Evaluation Metrics for Logistic Regression')

print(pd.DataFrame({'Val':Y_test,'Pred':classifier.predict(X_test)}))

## Decision Tree Classifier:

from sklearn.tree import DecisionTreeClassifier as dtc
classifier = dtc(max_depth=2)

X = tdata[['location','country','gender','age','vis_wuhan','from_wuhan',
           'symptom1','symptom2','symptom3','symptom4','symptom5','symptom6','diff_sym_hos']]
Y = tdata['death']

X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=10)
classifier.fit(X_train,np.array(Y_train).reshape(Y_train.shape[0],1))

## Evaluation of the Model:

pred = np.array(classifier.predict(X_test))

recall_dtc = rs(Y_test,pred)
precision_dtc = ps(Y_test,pred)
f1_dtc = fs(Y_test,pred)
ma_dtc = classifier.score(X_test,Y_test)

print('*** Evaluation metrics for test dataset ***\n')
print('Recall Score: ',recall_dtc)
print('Precision Score: ',precision_dtc)
print('F1 Score: ',f1_dtc)
print('Accuracy: ',ma_dtc)
a = pd.DataFrame(Y_test)
a['pred']= classifier.predict(X_test)
print('\n\tTable \n')
print(a.head())

import matplotlib.pyplot as plt

plt.bar(['Accuracy','F1 Score','Recall Score','Precision Score'],[ma_dtc,f1_dtc,recall_dtc,precision_dtc],color=['red','Blue','green','Yellow'])
plt.plot([ma_dtc,f1_dtc,recall_dtc,precision_dtc],color='black')
plt.title('Evaluation Metrics for Decision Tree')

## Decision Tree Visualization:

classifier.fit(X_train,np.array(Y_train).reshape(Y_train.shape[0],1))
from sklearn.externals.six import StringIO  
from IPython.display import Image  
from sklearn.tree import export_graphviz
import pydotplus

estimator = classifier
dot_data = StringIO()
export_graphviz(estimator, out_file=dot_data,  
                filled=True, rounded=True,
                special_characters=True)
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  
Image(graph.create_png(),width=250,height=200)

## SVM Classifier:

from sklearn import svm
classifier = svm.SVC()

X = tdata[['location','country','gender','age','vis_wuhan','from_wuhan',
           'symptom1','symptom2','symptom3','symptom4','symptom5','symptom6','diff_sym_hos']]
Y = tdata['death']

X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=10)
classifier.fit(X_train,np.array(Y_train).reshape(Y_train.shape[0],1))

## Evaluation of the Model:

pred = np.array(classifier.predict(X_test))

recall_svm = rs(Y_test,pred)
precision_svm = ps(Y_test,pred)
f1_svm = fs(Y_test,pred)
ma_svm = classifier.score(X_test,Y_test)

print('*** Evaluation metrics for test dataset ***\n')
print('Recall Score: ',recall_svm)
print('Precision Score: ',precision_svm)
print('F1 Score: ',f1_svm)
print('Accuracy: ',ma_svm)
a = pd.DataFrame(Y_test)
a['pred']= classifier.predict(X_test)
print('\n\tTable \n')
print(a.head())

import matplotlib.pyplot as plt

plt.bar(['Accuracy','F1 Score','Recall Score','Precision Score'],
        [ma_svm,f1_svm,recall_svm,precision_svm],color=['red','Blue','green','Yellow'])
plt.plot([ma_svm,f1_svm,recall_svm,precision_svm],color='black')
plt.title('Evaluation Metrics for Support Vector Machine')

## Gaussian Naive Bayes:

from sklearn.naive_bayes import GaussianNB
classifier = GaussianNB()

X = tdata[['location','country','gender','age','vis_wuhan',
           'from_wuhan','symptom1','symptom2','symptom3','symptom4','symptom5','symptom6','diff_sym_hos']]
Y = tdata['death']

X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=10)
classifier.fit(X_train,np.array(Y_train).reshape(Y_train.shape[0],1))

## Evaluation of the Model:

pred = np.array(classifier.predict(X_test))

recall_gnb = rs(Y_test,pred)
precision_gnb = ps(Y_test,pred)
f1_gnb = fs(Y_test,pred)
ma_gnb = classifier.score(X_test,Y_test)

print('*** Evaluation metrics for test dataset ***\n')
print('Recall Score: ',recall_gnb)
print('Precision Score: ',precision_gnb)
print('F1 Score: ',f1_gnb)
print('Accuracy: ',ma_gnb)
a = pd.DataFrame(Y_test)
a['pred']= classifier.predict(X_test)
print('\n\tTable \n')
print(a.head())

import matplotlib.pyplot as plt

plt.bar(['Accuracy','F1 Score','Recall Score','Precision Score'],
        [ma_gnb,f1_gnb,recall_gnb,precision_gnb],color=['red','Blue','green','Yellow'])
plt.plot([ma_gnb,f1_gnb,recall_gnb,precision_gnb],color='black')
plt.title('Evaluation Metrics for Gaussian Naive Bayes')

## Boosted Random Forest(Adaboost):
from sklearn.metrics import recall_score as rs
from sklearn.metrics import precision_score as ps
from sklearn.metrics import f1_score as fs
from sklearn.metrics import balanced_accuracy_score as bas
from sklearn.metrics import confusion_matrix as cm

rf = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=2, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=2, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=100,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False)
classifier = AdaBoostClassifier(rf,50,0.01,'SAMME.R',10)

X = tdata[['location','country','gender','age','vis_wuhan','from_wuhan','symptom1',
           'symptom2','symptom3','symptom4','symptom5','symptom6','diff_sym_hos']]
Y = tdata['death']

X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=0)
classifier.fit(X_train,np.array(Y_train).reshape(Y_train.shape[0],1))

## Evaluation of the Model:

pred = np.array(classifier.predict(X_test))

recall = rs(Y_test,pred)
precision = ps(Y_test,pred)
f1 = fs(Y_test,pred)
ma = classifier.score(X_test,Y_test)

print('*** Evaluation metrics for test dataset ***\n')
print('Recall Score: ',recall)
print('Precision Score: ',precision)
print('F1 Score: ',f1)
print('Accuracy: ',ma)
a = pd.DataFrame(Y_test)
a['pred']= classifier.predict(X_test)
print('\n\tTable \n')
print(a.head())

import matplotlib.pyplot as plt

plt.bar(['Accuracy','F1 Score','Recall Score','Precision Score'],
        [ma,f1,recall,precision],color=['red','blue','green','Yellow'])
plt.plot([ma,f1,recall,precision],color='black')
plt.title('Evaluation Metrics for Adaboost')

## Random Forest with Gradient Boosting:
from sklearn.metrics import recall_score as rs
from sklearn.metrics import precision_score as ps
from sklearn.metrics import f1_score as fs
from sklearn.metrics import balanced_accuracy_score as bas
from sklearn.metrics import confusion_matrix as cm
from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier

rf = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=2, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=2, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=100,
                       n_jobs=None, oob_score=False, random_state=None,
                       verbose=0, warm_start=False)
classifier = GradientBoostingClassifier(n_estimators=100)

X = tdata[['location','country','gender','age','vis_wuhan','from_wuhan',
           'symptom1','symptom2','symptom3','symptom4','symptom5','symptom6','diff_sym_hos']]
Y = tdata['death']

X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=0)
classifier.fit(X_train,np.array(Y_train).reshape(Y_train.shape[0],1))

## Evaluation of the Model:

pred = np.array(classifier.predict(X_test))

recall_rfgb = rs(Y_test,pred)
precision_rfgb = ps(Y_test,pred)
f1_rfgb = fs(Y_test,pred)
ma_rfgb = classifier.score(X_test,Y_test)

print('*** Evaluation metrics for test dataset ***\n')
print('Recall Score: ',recall_rfgb)
print('Precision Score: ',precision_rfgb)
print('F1 Score: ',f1_rfgb)
print('Accuracy: ',ma_rfgb)
a = pd.DataFrame(Y_test)
a['pred']= classifier.predict(X_test)
print('\n\tTable \n')
print(a.head())

import matplotlib.pyplot as plt

plt.bar(['Accuracy','F1 Score','Recall Score','Precision Score'],
        [ma_rfgb,f1_rfgb,recall_rfgb,precision_rfgb],color=['red','blue','green','Yellow'])
plt.plot([ma_rfgb,f1_rfgb,recall_rfgb,precision_rfgb],color='black')
plt.title('Evaluation Metrics for Gradient Boosting')

## Comparison of Evaluation Metrics for different Models:

import matplotlib.pyplot as plt
fig = plt.figure(figsize=(9,7))
plt.bar(['Logistic Regression','Decision Tree','R.F.(Adaboost)',
         'SVM','Gaussian NB','R.F.(Grad.boost)'],
        [f1_lr,f1_dtc,f1_svm,f1_gnb,f1,f1_rfgb],color=['red','lightgreen','darkblue','orange','lightBlue','Yellow'])
plt.plot(['Logistic Regression','Decision Tree','R.F.(Adaboost)',
          'SVM','Gaussian NB','R.F.(Grad.boost)'],
         [f1_lr,f1_dtc,f1,f1_svm,f1_gnb,f1_rfgb],color='purple',marker='D')
plt.plot(['Logistic Regression','Decision Tree','R.F.(Adaboost)',
          'SVM','Gaussian NB','R.F.(Grad.boost)'],
         [ma_lr,ma_dtc,ma,ma_svm,ma_gnb,ma_rfgb],color='red',marker='^')
plt.plot(['Logistic Regression','Decision Tree','R.F.(Adaboost)',
          'SVM','Gaussian NB','R.F.(Grad.boost)'],
         [precision_lr,precision_dtc,precision,precision_svm,precision_gnb,precision_rfgb],color='blue',marker='s')
plt.plot(['Logistic Regression','Decision Tree','R.F.(Adaboost)',
          'SVM','Gaussian NB','R.F.(Grad.boost)'],
         [recall_lr,recall_dtc,recall,recall_svm,recall_gnb,recall_rfgb],color='green',marker='P')
plt.legend(('F1 Score','Accuracy','Precision','Recall'))
plt.title('Comparison of different models performance')

plt.show(fig)